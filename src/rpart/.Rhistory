xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
View(dapply)
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart") # Establezco el Working Directory
# cargo el dataset que tiene la clase calculada !
dataset <- fread("competencia_01.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria_1 ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
View(dataset)
names(dataset)
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart") # Establezco el Working Directory
# cargo el dataset que tiene la clase calculada !
dataset <- fread("competencia_01.csv")
View(dataset)
names(dataset)
# cargo el dataset que tiene la clase calculada !
dataset <- fread("competencia_01.csv")
View(dataset)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart") # Establezco el Working Directory
# cargo el dataset que tiene la clase calculada !
dataset <- fread("competencia_01.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_002.csv",
sep = ","
)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
rm(list = ls()) # Borro todos los objetos
gc() # Garbage Collection
require("data.table")
require("rpart")
PARAM <- list()
PARAM$semilla <- 102191
PARAM$training_pct <- 70L  # entre  1L y 99L
PARAM$rpart <- list (
"cp" = -1, # complejidad minima
"minsplit" = 700, # minima cantidad de regs en un nodo para hacer el split
"minbucket" = 350, # minima cantidad de regs en una hoja
"maxdepth" = 8 # profundidad máxima del arbol
)
#  que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30),
#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar <- function(
data, division, agrupa = "",
campo = "fold", start = 1, seed = NA) {
if (!is.na(seed)) set.seed(seed)
bloque <- unlist(mapply(function(x, y) {
rep(y, x)
}, division, seq(from = start, length.out = length(division))))
data[, (campo) := sample(rep(bloque, ceiling(.N / length(bloque))))[1:.N],
by = agrupa
]
}
# Establezco el Working Directory, elija una carpeta de su
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset
dataset <- fread("./datasets/competencia_01.csv")
# cargo el dataset
dataset <- fread("competencia_01.csv")
# trabajo, por ahora, solo con 202104
dataset <- dataset[foto_mes==202104]
# particiono estratificadamente el dataset 70%, 30%
particionar(dataset,
division = c(PARAM$training_pct, 100L -PARAM$training_pct),
agrupa = "clase_ternaria",
seed = PARAM$semilla # aqui se usa SU semilla
)
# genero el modelo
# quiero predecir clase_ternaria a partir del resto
# fold==1  es training,  el 70% de los datos
modelo <- rpart("clase_ternaria ~ .",
data = dataset[fold == 1],
xval = 0,
control = PARAM$rpart # aqui van los parametros
)
# aplico el modelo a los datos de testing
prediccion <- predict(modelo, # el modelo que genere recien
dataset[fold == 2], # fold==2  es testing, el 30% de los datos
type = "prob"
) # type= "prob"  es que devuelva la probabilidad
# agrego una columna que es la de las ganancias
dataset[, ganancia := ifelse(clase_ternaria == "BAJA+2", 273000, -7000)]
# para testing agrego la probabilidad
dataset[fold == 2, prob_baja2 := prediccion[, "BAJA+2"]]
# calculo la ganancia en testing  qu es fold==2
ganancia_test <- dataset[fold == 2 & prob_baja2 > 0.025, sum(ganancia)]
# escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada <- ganancia_test / (( 100 - PARAM$training_pct ) / 100 )
estimulos <- dataset[fold == 2 & prob_baja2 > 0.025, .N]
aciertos <- dataset[fold == 2 & prob_baja2 > 0.025 & clase_ternaria == "BAJA+2", .N]
cat("Testing total: ", dataset[fold == 2, .N], "\n")
cat("Testing BAJA+2: ", dataset[fold == 2 & clase_ternaria == "BAJA+2", .N], "\n")
cat("Estimulos: ", estimulos, "\n")
cat("Aciertos (BAJA+2): ", aciertos, "\n")
cat("Ganancia en testing (normalizada): ", ganancia_test_normalizada, "\n")
# cargo el dataset
dataset <- fread("./datasets/competencia_01.csv")
# Arbol elemental con libreria  rpart
# Debe tener instaladas las librerias  data.table ,  rpart  y  rpart.plot
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart") # Establezco el Working Directory
# cargo el dataset que tiene la clase calculada !
dataset <- fread("dataset/competencia_01_feature_new.csv")
library(readr)
# cargo el dataset que tiene la clase calculada !
dataset <- fread("dataset/competencia_01_feature_new.csv")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("competencia_01_feature_new.csv")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart/dataset") # Establezco el Working Directory
competencia_01_feature_new <- read_csv("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
dataset <- read_csv("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
View(dataset)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
dataset <- read_csv("datasets/competencia_01_feature_new.csv")
View(dataset)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_004.csv",
sep = ","
)
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_005.csv",
sep = ","
)
dataset = dataset %>%
select(-ctarjeta_visa,-ctarjeta_master,-Master_msaldototal,-Visa_msaldototal,-ctarjeta_visa_transacciones,-ctarjeta_master_transacciones,-mtarjeta_visa_consumo,-mtarjeta_master_consumo)
dataset = dataset %>%
dplyr::select(-ctarjeta_visa,-ctarjeta_master,-Master_msaldototal,-Visa_msaldototal,-ctarjeta_visa_transacciones,-ctarjeta_master_transacciones,-mtarjeta_visa_consumo,-mtarjeta_master_consumo)
library(tidyverse)
dataset = dataset %>%
dplyr::select(-ctarjeta_visa,-ctarjeta_master,-Master_msaldototal,-Visa_msaldototal,-ctarjeta_visa_transacciones,-ctarjeta_master_transacciones,-mtarjeta_visa_consumo,-mtarjeta_master_consumo)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_006.csv",
sep = ","
)
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 500, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_007.csv",
sep = ","
)
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
library(tidyverse)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
# dataset = dataset %>%
#   dplyr::select(-ctarjeta_visa,-ctarjeta_master,-Master_msaldototal,-Visa_msaldototal,-ctarjeta_visa_transacciones,-ctarjeta_master_transacciones,-mtarjeta_visa_consumo,-mtarjeta_master_consumo)
dtrain <- dataset[foto_mes == 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# # grafico el arbol
# prp(modelo,
#     extra = 101, digits = -5,
#     branch = 1, type = 4, varlen = 0, faclen = 0
# )
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# prediccion es una matriz con TRES columnas,
# llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
# cada columna es el vector de probabilidades
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_008.csv",
sep = ","
)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
### que pasa si solo predigo baja?
dataset[ , clase_ternaria := ifelse( clase_ternaria=="CONTINUA", "NEG", "POS" ) ]
View(dataset)
### que pasa si solo predigo baja?
dataset[ , clase_ternaria := ifelse( clase_ternaria=="CONTINUA", 0, 1 ) ]
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja := prediccion[, 1]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_009.csv",
sep = ","
)
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
### que pasa si solo predigo baja?
dataset[ , clase_ternaria := ifelse( clase_ternaria=="CONTINUA", 0, 1 ) ]
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 450, # minima cantidad de registros para que se haga el split
minbucket = 150, # tamaño minimo de una hoja
maxdepth = 10  # profundidad maxima del arbol
)
# feature importance
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# feature importance
importance <- modelo$variable.importance
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja := prediccion[, 1]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_010.csv",
sep = ","
)
