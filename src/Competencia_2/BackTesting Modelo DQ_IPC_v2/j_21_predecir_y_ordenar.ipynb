{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_xvJXPhCkMA"
   },
   "source": [
    "# Predecir y ordenar \n",
    "\n",
    "### Autor: Federico Picado\n",
    "### Fecha de última modificación: 15/11/2024\n",
    "### Descripción:\n",
    "\n",
    "Este script predice N modelos donde solo cambia la semilla y mergea los resultados segun la metrica que escoja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRTSvXdLHkpB"
   },
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yMU00Fl7IIfm"
   },
   "outputs": [],
   "source": [
    "mes_test = 202106 # mes donde se predice\n",
    "\n",
    "# nombre de la carpeta donde se guardaron los modelos\n",
    "nombre_carpeta = \"modelo_DQ_IPC_v2\" # Cambiar\n",
    "\n",
    "# nombre de la carpeta donde se guardan los resultados para cada modelo\n",
    "dataset_folder=\"prediccion_DQ_IPC_v2\"\n",
    "\n",
    "# metricas, pueden ser promedio, mediana, max, bootstrap. Si eligen bootstrap, tambien elegir n_bootstrap\n",
    "metrica_elegida=\"promedio\"\n",
    "n_bootstrap=None # cambiar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH5VivJSIM42"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fedepicado/.venv/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Ya en el input se ejecutan cosas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/fedepicado/'\n",
    "modelos_path = base_path + 'buckets/b1/exp/'\n",
    "predicciones_path = base_path + 'buckets/b1/predicciones/'\n",
    "db_path = base_path + 'buckets/b1/db/'\n",
    "dataset_path = base_path + 'buckets/b1/datasets/'\n",
    "dataset_file = 'competencia_02_DQ_IPC_v2.parquet'\n",
    "full_path = dataset_path + dataset_file\n",
    "\n",
    "\n",
    "## Carpeta donde guardo voy a guardar las predicciones del modelo que entrene\n",
    "nombre_carpeta=\"modelo_DQ_IPC_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte podria estar en procesamiento pero creo que aca se va a poder modificar mejor en el caso que el modelo no sea el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### El modelo que entre yo es un LGBM, creando la clase binaria y separe los datos para predecir\n",
    "data = pd.read_parquet(dataset_path + dataset_file)\n",
    "df=data.copy()\n",
    "\n",
    "df['clase_peso'] = 1.0\n",
    "df['clase_binaria'] = 0\n",
    "df['clase_binaria'] = np.where(df['clase_ternaria'] == 'CONTINUA', 0, 1)\n",
    "\n",
    "df.loc[df['clase_binaria'] == 1, 'clase_peso'] = 1.0001\n",
    "\n",
    "test_data = df[df['foto_mes'] == mes_test]\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ6MUhENI0Ya"
   },
   "source": [
    "## Output\n",
    "\n",
    "< Archivos, bases de datos, modelos que va a generar el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZT3kxlkFIv4p"
   },
   "outputs": [],
   "source": [
    "predicciones_path = base_path + 'buckets/b1/predicciones/'\n",
    "#dentro de predicciones_path se va a crear una carpeta para guardar las predicciones de cada modelo segun la metrica que elija. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#levantar todos los modelos que haya dentro de la carpeta correspondiente\n",
    "\n",
    "def cargar_modelos_desde_carpeta(modelos_path, nombre_carpeta):\n",
    "    \"\"\"\n",
    "    Carga todos los modelos de LightGBM guardados en archivos dentro de la carpeta especificada.\n",
    "    \n",
    "    Parámetros:\n",
    "    - modelos_path: str, ruta base donde se encuentra la carpeta de modelos.\n",
    "    - nombre_carpeta: str, el nombre de la subcarpeta donde se guardaron los modelos.\n",
    "    \n",
    "    Retorna:\n",
    "    - modelos_cargados: diccionario con los modelos cargados, donde la clave es el nombre del archivo y el valor es el modelo.\n",
    "    \"\"\"\n",
    "    # Construir la ruta completa de la carpeta de modelos\n",
    "    ruta_carpeta = os.path.join(modelos_path, nombre_carpeta)\n",
    "    \n",
    "    modelos_cargados = {}\n",
    "\n",
    "    # Verificar que la carpeta existe\n",
    "    if not os.path.exists(ruta_carpeta):\n",
    "        print(f\"La carpeta {ruta_carpeta} no existe.\")\n",
    "        return modelos_cargados\n",
    "\n",
    "    # Listar y cargar solo archivos que terminan en '.txt'\n",
    "    archivos_modelo = [f for f in os.listdir(ruta_carpeta) if f.endswith('.txt')]\n",
    "    for archivo in archivos_modelo:\n",
    "        ruta_del_modelo = os.path.join(ruta_carpeta, archivo)\n",
    "        modelo = lgb.Booster(model_file=ruta_del_modelo)\n",
    "        modelos_cargados[archivo] = modelo\n",
    "        print(f\"Modelo cargado desde: {ruta_del_modelo}\")\n",
    "    \n",
    "    return modelos_cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: /home/fedepicado/buckets/b1/exp/modelo_DQ_1/modelo_DQ_1_65033.txt\n",
      "Modelo cargado desde: /home/fedepicado/buckets/b1/exp/modelo_DQ_1/modelo_DQ_1_75011.txt\n"
     ]
    }
   ],
   "source": [
    "modelos_cargados = cargar_modelos_desde_carpeta(modelos_path, nombre_carpeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_y_ordenar_modelos(modelos_entrenados, X_test, metrica=\"promedio\", n_bootstrap=0,\n",
    "                               predicciones_path=predicciones_path, nombre_carpeta=nombre_carpeta):\n",
    "    \"\"\"\n",
    "    Realiza predicciones con modelos entrenados de LightGBM y crea un DataFrame final\n",
    "    con la probabilidad obtenida mediante una métrica seleccionada para cada cliente.\n",
    "    También permite guardar el DataFrame final en un archivo CSV en una carpeta específica.\n",
    "    \n",
    "    Parámetros:\n",
    "    - modelos_entrenados: dict, contiene los modelos entrenados con las semillas como nombres.\n",
    "    - X_test: DataFrame, conjunto de test.\n",
    "    - metrica: str, criterio de selección de la probabilidad final (\"promedio\", \"mediana\", \"max\" o \"bootstrap\").\n",
    "    - n_bootstrap: int, número de muestras bootstrap para el ensamble (por defecto 0, sin bootstrap).\n",
    "    - predicciones_path: str, ruta base donde se guardarán las predicciones.\n",
    "    - nombre_carpeta: str, nombre de la subcarpeta donde se guardarán las predicciones.\n",
    "    \n",
    "    Retorna:\n",
    "    - df_final: DataFrame con 'numero_de_cliente' y la probabilidad seleccionada ('Probabilidad') para cada cliente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Asegurarse de que 'numero_de_cliente' esté en X_test\n",
    "    if 'numero_de_cliente' not in X_test.columns:\n",
    "        raise ValueError(\"La columna 'numero_de_cliente' debe estar presente en X_test\")\n",
    "    \n",
    "    # Obtener las características utilizadas por los modelos\n",
    "    columnas_modelo = modelos_entrenados[list(modelos_entrenados.keys())[0]].feature_name()\n",
    "    \n",
    "    # Asegurarse de que X_test tenga las mismas columnas que los datos de entrenamiento\n",
    "    X_test_modelo = X_test[columnas_modelo].copy()\n",
    "    \n",
    "    # Crear un DataFrame para almacenar todas las predicciones\n",
    "    todas_predicciones = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente']})\n",
    "    \n",
    "    # Para cada modelo entrenado, hacemos predicciones\n",
    "    for nombre_modelo, model in modelos_entrenados.items():\n",
    "        try:\n",
    "            # Hacer predicciones sobre el conjunto de test\n",
    "            predicciones = model.predict(X_test_modelo)\n",
    "            \n",
    "            # Agregar las predicciones al DataFrame\n",
    "            todas_predicciones[nombre_modelo] = predicciones\n",
    "            \n",
    "            print(f\"Predicciones realizadas para {nombre_modelo}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {nombre_modelo}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Seleccionar la probabilidad final según el parámetro 'metrica'\n",
    "    if metrica == \"promedio\":\n",
    "        todas_predicciones['Probabilidad'] = todas_predicciones.iloc[:, 1:].mean(axis=1)\n",
    "    elif metrica == \"mediana\":\n",
    "        todas_predicciones['Probabilidad'] = todas_predicciones.iloc[:, 1:].median(axis=1)\n",
    "    elif metrica == \"max\":\n",
    "        todas_predicciones['Probabilidad'] = todas_predicciones.iloc[:, 1:].max(axis=1)\n",
    "    elif metrica == \"bootstrap\":\n",
    "        if n_bootstrap <= 0:\n",
    "            raise ValueError(\"Debe especificar un número positivo de muestras bootstrap para el ensamble.\")\n",
    "        else:\n",
    "            # Realizar ensamble de bootstrap\n",
    "            predicciones_bootstrap = []\n",
    "            num_modelos = len(modelos_entrenados)\n",
    "            nombres_modelos = list(modelos_entrenados.keys())\n",
    "            for i in range(n_bootstrap):\n",
    "                # Seleccionar modelos con reemplazo\n",
    "                modelos_seleccionados = np.random.choice(nombres_modelos, size=num_modelos, replace=True)\n",
    "                # Promediar las predicciones de los modelos seleccionados\n",
    "                promedio_bootstrap = todas_predicciones[modelos_seleccionados].mean(axis=1)\n",
    "                predicciones_bootstrap.append(promedio_bootstrap)\n",
    "            # Promediar los resultados de las muestras bootstrap\n",
    "            todas_predicciones['Probabilidad'] = pd.concat(predicciones_bootstrap, axis=1).mean(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"La métrica debe ser 'promedio', 'mediana', 'max' o 'bootstrap'\")\n",
    "    \n",
    "    # Crear el DataFrame final con 'numero_de_cliente' y la probabilidad seleccionada\n",
    "    df_final = todas_predicciones[['numero_de_cliente', 'Probabilidad']]\n",
    "    \n",
    "    # Ordenar el DataFrame final por 'Probabilidad' de forma descendente\n",
    "    df_final = df_final.sort_values(by='Probabilidad', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Si se proporciona predicciones_path, guardar el archivo\n",
    "    if predicciones_path is not None:\n",
    "        # Crear la carpeta completa (predicciones_path + nombre_carpeta) si no existe\n",
    "        full_path = os.path.join(predicciones_path, nombre_carpeta)\n",
    "        os.makedirs(full_path, exist_ok=True)\n",
    "        \n",
    "        # Crear el nombre del archivo usando la métrica\n",
    "        file_name = f\"predicciones_{metrica}.csv\"\n",
    "        file_path = os.path.join(full_path, file_name)\n",
    "        \n",
    "        # Guardar el DataFrame en un archivo CSV\n",
    "        df_final.to_csv(file_path, index=False)\n",
    "        print(f\"El DataFrame final ha sido guardado en: {file_path}\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones realizadas para modelo_DQ_1_65033.txt\n",
      "Predicciones realizadas para modelo_DQ_1_75011.txt\n",
      "El DataFrame final ha sido guardado en: /home/fedepicado/buckets/b1/predicciones/modelo_DQ_1/predicciones_promedio.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_de_cliente</th>\n",
       "      <th>Probabilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>560453687</td>\n",
       "      <td>9.528198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1134986809</td>\n",
       "      <td>9.462462e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1224175879</td>\n",
       "      <td>9.305245e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1026240450</td>\n",
       "      <td>9.262970e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>883803687</td>\n",
       "      <td>9.244647e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164871</th>\n",
       "      <td>914491324</td>\n",
       "      <td>1.618978e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164872</th>\n",
       "      <td>477105711</td>\n",
       "      <td>1.547344e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164873</th>\n",
       "      <td>486163687</td>\n",
       "      <td>1.444123e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164874</th>\n",
       "      <td>550904181</td>\n",
       "      <td>1.154428e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164875</th>\n",
       "      <td>591957083</td>\n",
       "      <td>1.032068e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        numero_de_cliente  Probabilidad\n",
       "0               560453687  9.528198e-01\n",
       "1              1134986809  9.462462e-01\n",
       "2              1224175879  9.305245e-01\n",
       "3              1026240450  9.262970e-01\n",
       "4               883803687  9.244647e-01\n",
       "...                   ...           ...\n",
       "164871          914491324  1.618978e-08\n",
       "164872          477105711  1.547344e-08\n",
       "164873          486163687  1.444123e-08\n",
       "164874          550904181  1.154428e-08\n",
       "164875          591957083  1.032068e-08\n",
       "\n",
       "[164876 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definir la ruta donde se guardan las predicciones y el nombre de la carpeta donde se van a guardar\n",
    "predecir_y_ordenar_modelos(modelos_cargados, X_test, metrica=metrica_elegida, n_bootstrap=n_bootstrap)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
