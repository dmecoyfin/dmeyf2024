{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1ycmADVNAZNf5paPi258hLERfhHZ-T_VP","authorship_tag":"ABX9TyPuoUK6m5dj5FjFK7yJGZjG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Sobre árboles de decisión\n","\n","Comenzaremos revisando algunos conceptos básicos sobre el funcionamiento de los árboles de decisión. A medida que avancemos en las clases, exploraremos sus diversas características y desafíos, con el objetivo de comprender por qué, en problemas de modelado de datos tabulares, siguen siendo el estado del arte, superando incluso a los modelos más complejos de redes neuronales.\n","\n","Empezaremos con un hermosa visualización de como funcionan gracias a la gente de **R2D3**\n","\n","[Cómo funciona un árbol de decisión](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n","\n","Y luego empezaremos a trabajar con nuestro conjunto de datos para *tratar* de modelar uno. Para eso, debemos iniciar el entorno\n","\n","## Setup"],"metadata":{"id":"EhPBcYQ-g3UY"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n"],"metadata":{"id":"94YcT0Ovg5yy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Variables importantes"],"metadata":{"id":"1dbiRMBr4d7K"}},{"cell_type":"code","source":["dataset_path = '/home/aleb/DMEyF/2024/datos/' # '/content/drive/MyDrive/DMEyF/2024/datos/'\n","dataset_file = 'competencia_01.csv'\n","\n","ganancia_acierto = 273000\n","costo_estimulo = 7000"],"metadata":{"id":"Squ-QWasLSmi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cargamos el **dataset**, vamos a trabajar en esta ocasión solo con un periodo: **202104**.\n","\n","Algo que va a generar algo de confusión es que no separemos con **Train / Test** en esta ocasión.\n","\n","**NO ENTRE EN PÁNICO**, en esta cursada se le dedicará mucho tiempo a entender y combatir el problema del overfitting. Pero no hoy."],"metadata":{"id":"xoTRzOdk5qB-"}},{"cell_type":"code","source":["data = pd.read_csv(dataset_path+dataset_file)\n","data = data[data['foto_mes'] == 202104]\n","\n","X = data.drop('clase_ternaria', axis=1)\n","y = data['clase_ternaria']\n"],"metadata":{"id":"My2yi18BTf4Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos que porcentaje ocupa de nuestro dataset, el target que queremos predecir"],"metadata":{"id":"VsPgFbtvEa3L"}},{"cell_type":"code","source":["data['clase_ternaria'].value_counts(normalize=True)*100"],"metadata":{"id":"MRxAxyvuEXg-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **¿Había trabajado con un target tan poco representativo?**\n","* **¿Cree que esto es algo común o tan solo una rareza?**"],"metadata":{"id":"8o99j7vCFNRX"}},{"cell_type":"markdown","source":["## Primer árbol\n","Con nuestros datos ya cargados en **memoria**, podemos dedicarnos a generar nuestro primer árbol\n","\n","### Párametros\n","\n","(gentileza de chat-gpt en un 90%)\n","\n","El **DecisionTreeClassifier** en scikit-learn tiene varios parámetros que controlan cómo se construye el árbol de decisión. A continuación te explico los más importantes:\n","\n","1. **criterion**: Este parámetro define la función que se usa para medir la calidad de una división (split). Las opciones principales son:\n","\n"," * **gini** (predeterminado): Utiliza el índice de Gini, que mide la impureza de las particiones. Un valor de Gini más bajo significa que una partición es más pura.\n"," * **entropy**: Utiliza la entropía de la información, relacionada con el concepto de ganancia de información. Se enfoca en reducir la incertidumbre en las particiones.\n","\n"," [Explicación de ambos criterios](https://www.geeksforgeeks.org/gini-impurity-and-entropy-in-decision-tree-ml/)\n","\n","2. **max_depth**: Controla la profundidad máxima del árbol.\n","\n","3. **min_samples_split**: Especifica el número mínimo de muestras que un nodo debe tener para poder dividirse.\n","\n","4. **min_samples_leaf**: Define el número mínimo de muestras que debe tener una hoja (nodo final).\n","\n","5. **max_features**: Indica el número máximo de características que el modelo debe considerar para hacer la mejor división.\n","\n","6. **max_leaf_nodes**: Especifica el número máximo de nodos hoja que el árbol puede tener.\n","\n","7. **random_state**: Fija la semilla utilizada por el generador de números aleatorios, lo que garantiza que los resultados del entrenamiento sean reproducibles.\n","\n","8. **ccp_alpha**: Parámetro de complejidad de poda mínima, utilizado para la poda de árboles de decisión después de que se hayan construido. Un valor más alto lleva a árboles más pequeños.\n","\n"," **EN LA CURSADA CREEMOS QUE LA INTELIGENCIA DEL ALUMNO CORRELACIONA DE FORMA NEGATIVA A VALOR QUE SETEA ESTE PARÁMETRO**\n","\n","Queda de tarea para el alumnado jugar con algunas parametrías. Usaremos a continuación una simple\n","\n","### Modelo"],"metadata":{"id":"HlZgjKChg_Ll"}},{"cell_type":"code","source":["model = DecisionTreeClassifier(criterion='gini',\n","                               random_state=17,\n","                               min_samples_split=80,\n","                               min_samples_leaf=1,\n","                               max_depth=5)\n","\n","model.fit(X, y)"],"metadata":{"id":"X3OjBwTNTn-8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualización\n","\n","Todo es mucho más bonito si tiene colores"],"metadata":{"id":"-e4pZQOt8IXX"}},{"cell_type":"code","source":["plt.figure(figsize=(40,20))\n","plot_tree(model, feature_names=X.columns, filled=True, class_names=model.classes_, rounded=True, impurity=False) #,  proportion=True)\n","plt.show()"],"metadata":{"id":"xOZtrAED-qu7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Midiendo el modelo\n","\n","Mirando tan solo la visualización\n","\n","* **¿Qué tan bien performó el modelo?**\n","* **¿Qué tan bien detectó los CONTINUA?**\n","* **¿Qué tan bien detectó los BAJA+2?**\n","\n","Para meter manos en la masa, vamos a llevar las hojas del modelo a una tabla, para esto haremos uso de una función auxiliar"],"metadata":{"id":"YzRwScOHI6Te"}},{"cell_type":"code","source":["def get_leaf_info(tree):\n","    tree_ = tree.tree_\n","    class_names = model.classes_\n","    leaf_info = []\n","    for i in range(tree_.node_count):\n","        if tree_.children_left[i] == _tree.TREE_LEAF:\n","            class_counts = tree_.value[i][0]\n","            predicted_class_index = class_counts.argmax()\n","            predicted_class = class_names[predicted_class_index]\n","            row = {\n","                'Node': i,\n","                'Samples': int(tree_.n_node_samples[i]),\n","                'Predicted Class': predicted_class\n","            }\n","            for j, class_name in enumerate(class_names):\n","                row[class_name] = int(class_counts[j])\n","            leaf_info.append(row)\n","    return pd.DataFrame(leaf_info)\n","\n","leaf_df = get_leaf_info(model)\n","leaf_df\n"],"metadata":{"id":"a1hx0HjvJuyu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora en el dataset **leaf_ds** tenemos cada nodo terminal (hoja).\n","\n","Vemos que según el modelo, no deberíamos mandar ningún estímulo, dado que no detectó ningún **BAJA+2**. Sin embargo dudaremos de esto y veremos cuanta plata nos hubiera dejado cada hoja, si enviáramos a los clientes que cayeron en esta.\n"],"metadata":{"id":"fHDDMEUSJ1jA"}},{"cell_type":"code","source":["leaf_df[\"ganancia\"] = ganancia_acierto*leaf_df[\"BAJA+2\"] - costo_estimulo*leaf_df[\"BAJA+1\"] + -costo_estimulo*leaf_df[\"CONTINUA\"]\n","leaf_df.sort_values(\"ganancia\", ascending=False, inplace=True)\n","leaf_df"],"metadata":{"id":"tBvgtMDSKlUh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vaya! no son pocos las hojas que hubieran dado ganancia positiva, y todas a su vez estuvieron mal clasificadas por el modelo.\n","\n","Veamos de calcular la probabilidad de **BAJA+2** por cada hoja"],"metadata":{"id":"fBtTeYb3Kqn0"}},{"cell_type":"code","source":["leaf_df[\"prob_baja_2\"] = leaf_df[\"BAJA+2\"]/leaf_df[\"Samples\"]\n","leaf_df.sort_values(\"prob_baja_2\", ascending=False, inplace=True)\n","leaf_df"],"metadata":{"id":"y67lIZAMK7YU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","Finalmente calculemos la ganancia acumulada para cada posible punto de corte:"],"metadata":{"id":"fyjwfpFYLMgT"}},{"cell_type":"code","source":["leaf_df['gan_acumulada'] = leaf_df['ganancia'].cumsum()\n","leaf_df"],"metadata":{"id":"BPdcKyTVLMIc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **¿Cuál es la ganancia máxima que puede obtener con este modelo?**\n","* **¿Nota alguna relación con la probabilidad de corte óptima discutida en la clase anterior?**\n"],"metadata":{"id":"VzY4d06fMQHt"}},{"cell_type":"markdown","source":["### Matrices de Confusión\n","\n","Todos ya sabemos que es son las matrices de confusión y como usando los valores de la misma, podemos  [calcular varios estadísticos](https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion)\n","\n","Una diferencia a lo trabajado hasta ahora en la maestría, es que por cada modelo no vamos a generar 1 matriz de confusión, sino múltiples, 1 por cada punto de corte.\n","\n","Para eso tenemos que proceder:\n","* Agrupar los buenos y los malos, ya que la mayoría de los indicadores son binarios\n","* Calcular los valores: **TP, TN, FP y FN**"],"metadata":{"id":"YKpbiW6TNDvG"}},{"cell_type":"code","source":["leaf_df[\"evento\"] = leaf_df[\"BAJA+2\"]\n","leaf_df[\"no_evento\"] = leaf_df[\"CONTINUA\"] + leaf_df[\"BAJA+1\"]\n","\n","leaf_df[\"evento_acum\"] = leaf_df[\"evento\"].cumsum()\n","leaf_df[\"no_evento_acum\"] = leaf_df[\"no_evento\"].cumsum()\n","\n","total_evento = leaf_df[\"evento\"].sum()\n","total_noevento = leaf_df[\"no_evento\"].sum()\n","\n","leaf_df['evento_restantes'] = total_evento - leaf_df[\"evento_acum\"]\n","leaf_df['noevento_restantes'] = total_noevento - leaf_df[\"no_evento_acum\"]\n","\n","leaf_df[\"TP\"] = leaf_df[\"evento_acum\"]\n","leaf_df[\"TN\"] = leaf_df[\"noevento_restantes\"]\n","leaf_df[\"FP\"] = leaf_df[\"no_evento_acum\"]\n","leaf_df[\"FN\"] = leaf_df[\"evento_restantes\"]\n","\n","leaf_df"],"metadata":{"id":"qrevFpAHPl5h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nos quedamos con una tabla reducida"],"metadata":{"id":"FjxE9S69R6Fz"}},{"cell_type":"code","source":["leaf2_df = leaf_df[[\"prob_baja_2\", \"TP\", \"TN\", \"FP\", \"FN\"]]\n","leaf2_df.sort_values(\"prob_baja_2\", ascending=False, inplace=True)\n","leaf2_df"],"metadata":{"id":"k6ziJF_yQq_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Con esta tabla podemos nos solo calcular los indicadores clásicos, sino que podemos hacer por cada punto de corte, dibujar la curva y establecer cuál es el optimo punto de corte que máximiza el métrica.\n"],"metadata":{"id":"jrUuOCGcShHz"}},{"cell_type":"markdown","source":["\n","#### curva ROC\n","\n","La curva ROC (Receiver Operating Characteristic) es una herramienta gráfica utilizada en ciencia de datos para evaluar el rendimiento de un modelo de clasificación binaria. Es particularmente útil para entender  el trade-off entre cuánto podemos ganar, en función de cuanto estamos dispuestos a perder.\n","\n","Se dibuja como **Tasa de Falsos Positivos** contra **Tasa de Verdaderos Positivos**\n"],"metadata":{"id":"tTCFVi6kcyx_"}},{"cell_type":"code","source":["leaf2_df['TPR'] = leaf2_df['TP'] / (leaf2_df['TP'] + leaf2_df['FN'])\n","leaf2_df['FPR'] = leaf2_df['FP'] / (leaf2_df['FP'] + leaf2_df['TN'])\n","\n","sns.lineplot(x='FPR', y='TPR', data=leaf2_df)\n","plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","plt.xlabel('Tasa de Falsos Positivos')\n","plt.ylabel('Tasa de Verdaderos Positivos')\n","plt.title('Curva ROC')\n","plt.grid(True)\n","plt.show()\n","\n","# Nota: Es probable que los valores de FPR y TPR esten lejos del [0,0] y [1,1]\n","# si ese es su caso, debe agregarlos a mano a la tabla"],"metadata":{"id":"dRU8i8fxdVMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* La línea de identidad indica el comportamiento de un clasificador que no tiene ninguna habilidad para distinguir entre las clases positivas y negativas.\n","* Es una métrica independiente de la distribución de clases: La curva ROC no depende de la distribución de las clases en los datos (balance de clases), lo que la hace útil en situaciones donde las clases están desbalanceadas.\n","* Es una evaluación global del modelo: La curva ROC proporciona una visión más completa del rendimiento del modelo.\n","\n","No todo son rosas, si queremos comparar 2 modelos, mirar curvas puede ser complejo. Por esto mismo, se suele calcular la métrica **AUC** (Area Under the Curve) como un estatístico de la calidad del modelo."],"metadata":{"id":"Iheqza_zdv3d"}},{"cell_type":"code","source":["np.trapz(leaf2_df['TPR'], leaf2_df['FPR']) # calcula el área de bajo de la curva"],"metadata":{"id":"1QiKEwJNe103"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* AUC = 1: El modelo clasifica perfectamente todas las instancias. Más cerca de 1 se encuentra el indicador, mejor.\n","* AUC = 0.5: El modelo no tiene capacidad discriminativa; su rendimiento es equivalente a realizar una clasificación aleatoria.\n","* AUC < 0.5: Indica un rendimiento peor que una clasificación aleatoria (dale vuelta a la clase).\n","* Más de una curva puede tener la misma AUC, se suele elegir a la más empinada"],"metadata":{"id":"6PnUdSyAfQa9"}},{"cell_type":"markdown","source":["### Tarea\n","* Cambie los parámetros del modelo y vea los impactos en cada una de las métricas.\n"," * ¿Cuál fue el modelo que dió más ganancia económica? ¿El peor?\n"," * ¿Cuál fue el modelo que dió mayor AUC? ¿El peor?\n","* Calcule, dibuje y encuentre el punto de corte óptimo para:\n"," * Accuracy\n"," * Sensibilidad\n"," * Especificidad\n"," * F1-Score"],"metadata":{"id":"W4CPBoC4cHYE"}},{"cell_type":"markdown","source":["## Explorando el dataset\n","\n","En esta última parte, vamos a realizar un **EDA** rápido del dataset.\n","\n"],"metadata":{"id":"0iLnSRto_J9y"}},{"cell_type":"markdown","source":["### Sumarizando\n","\n","Empezamos por un pantallazo sobre todas las variables, con una **sumarización**, agregando 2 estadísticos muy importantes que no trae por defecto **Pandas**\n","\n","* **Número de valores únicos de una variables**: Muchas veces variables categóricas están codificadas en variables numéricas. Este indicador nos ayudará a detectarlas\n","* **Número de missing values**: Que cantidad de registros tienen valores numéricos y cuales tiene faltantes. El tratamiento (o no) de missings es uno de los temas que navegarán en los **experimentos colectivos**\n","\n","Navegue la tabla a la par de el **diccionario de datos**. Los alumnos tienen a subestimar el poder de entender el conjunto de datos a la hora de hacer un buen modelo."],"metadata":{"id":"Swu-4n2XI3Rn"}},{"cell_type":"code","source":["desc_stats = data.describe(include='all') # Calcula estadísticas descriptivas básicas\n","missing_values = data.isnull().sum() # Calcula el número de valores faltantes por columna\n","unique_values = data.nunique() # Calcula el número de valores distintos por columna\n","\n","# Combina las estadísticas en un solo DataFrame\n","summary_table = pd.DataFrame({\n","    'Missing Values': missing_values,\n","    'Unique Values': unique_values\n","})\n","\n","pd.concat([summary_table.transpose(), desc_stats], axis=0).transpose()\n"],"metadata":{"id":"G8MCcoXW_qzt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explorando las variables más importantes del modelo\n","\n","Vamos a profundizar sobre las variables utilizadas por el modelo. Si las eligió el modelo, seguro nos ayudará a entender un poco más los datos, no?\n","\n","Para este fin, vamos a obtener la importancia de variable del modelo"],"metadata":{"id":"8qVMXcYIBRCw"}},{"cell_type":"code","source":["feature_importances = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n","feature_importances.sort_values('importance', ascending=False)\n"],"metadata":{"id":"uVK70joZXda7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tomaremos algunas para hacer un doble click\n","\n","#### ctrx_quarter\n","\n","**¿Qué significa esta variable?**\n","\n","Cómo se trata de una variable numéricas, vamos a graficar la densidad por cada clase:"],"metadata":{"id":"4GdGHRP3CDOd"}},{"cell_type":"code","source":["g = sns.FacetGrid(data, row=\"clase_ternaria\", height=3, aspect=2)\n","g.map(sns.histplot, \"ctrx_quarter\", stat='density')"],"metadata":{"id":"D8D2hOv0z_Tb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **¿Qué conclusiones saca de los gráficos?**\n","* **¿Detecta algún patrón en la baja de los clientes?**\n","\n","#### Visa_status\n","\n","**¿Qué significa esta variable?**\n","\n","Esta variable es númerica, pero tiene una baja cardinalidad. Vamos a estudiarla de otra manera"],"metadata":{"id":"BJH5BbhHCkYo"}},{"cell_type":"code","source":["pd.crosstab(data['Visa_status'], data['clase_ternaria'])"],"metadata":{"id":"WI1rT-Uh1-k5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **¿Qué conclusiones saca de esta tabla?**\n","* **¿Detecta algún patrón en la baja de los clientes?**\n","* **¿Puede generar una regla a mano que le haga ganar plata al banco?** si es así, ¿Cuánta plata ganaría?"],"metadata":{"id":"6fRIZPLnC-tb"}},{"cell_type":"markdown","source":["#### mpasivos_margen\n","\n","**¿Qué significa esta variable?**\n","\n","Esta variable también es númerica. Intente gráficar un diagrama de densidad y verá que no es algo que vaya a funcionar muy bien.\n","\n","Frente a un escenario así podemos recurrir a los todo poderosos **box-plots**"],"metadata":{"id":"cXuvbT1GDS-B"}},{"cell_type":"code","source":["sns.boxplot(x='clase_ternaria', y='mpasivos_margen', data=data)"],"metadata":{"id":"xz3TOXkuFH5O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ok... esto no es muy ilustrativo.\n","\n","* **¿Qué son esos círculitos?**\n","\n","Probemos podar un poco la variable:"],"metadata":{"id":"a_NXJmduFgt7"}},{"cell_type":"code","source":["lower_bound = data['mpasivos_margen'].quantile(0.05)\n","upper_bound = data['mpasivos_margen'].quantile(0.95)\n","\n","filtered_data = data[(data['mpasivos_margen'] >= lower_bound) & (data['mpasivos_margen'] <= upper_bound)]\n","sns.boxplot(x='clase_ternaria', y='mpasivos_margen', data=filtered_data)"],"metadata":{"id":"SrPWMsj144p3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **¿Qué paso en el código anterior?**\n","* **¿Qué interpretación hace sobre el gráfico?**\n","\n","### Tarea\n","Esto es solo el comienzo. Tiene que hacer un video a **Miranda** y para eso debe entender bien los datos. Continue con el **EDA**.\n","\n","* Sume al análisis los periodos descartados\n","* ¿Se pueden construir features que den más luz a los modelos a detectar las futuras bajas?"],"metadata":{"id":"IeUWIRKRF4E6"}}]}