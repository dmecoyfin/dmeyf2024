setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1")
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
library(tidyverse)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
library(tidyverse)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
getwd()=='C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/Competencia_1'
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_012.csv",
sep = ","
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
dtrain <- dataset[foto_mes == 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 500, # minima cantidad de registros para que se haga el split
minbucket = 200, # tamaño minimo de una hoja
maxdepth = 10  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_013.csv",
sep = ","
)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 500, # minima cantidad de registros para que se haga el split
minbucket = 200, # tamaño minimo de una hoja
maxdepth = 10  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_014.csv",
sep = ","
)
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
library(tidyverse)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_lag_delta.csv")
View(dataset)
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_lag_delta.csv")
require("data.table")
require("rpart")
require("rpart.plot")
library(readr)
library(tidyverse)
setwd("C:/Users/Federico/Desktop/Repositorios/dmeyf2024/src/rpart")
# cargo el dataset que tiene la clase calculada !
dataset <- fread("datasets/competencia_01_feature_new.csv")
dtrain <- dataset[foto_mes <= 202104] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202106] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 500, # minima cantidad de registros para que se haga el split
minbucket = 200, # tamaño minimo de una hoja
maxdepth = 10  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 200, # minima cantidad de registros para que se haga el split
minbucket = 100, # tamaño minimo de una hoja
maxdepth = 20  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 250, # minima cantidad de registros para que se haga el split
minbucket = 150, # tamaño minimo de una hoja
maxdepth = 7  # profundidad maxima del arbol
)
importance <- modelo$variable.importance
importance <- round(100 * importance / sum(importance), 1)
importance[importance >= 1]
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = "./exp/KA2001/K101_015.csv",
sep = ","
)
